{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = cv2.imread('./data/0342/IMG_0342_1.tif', cv2.IMREAD_GRAYSCALE)\n",
    "img = np.zeros((head.shape[0], head.shape[1], 4), dtype='uint8')\n",
    "\n",
    "img[:,:,0] = head\n",
    "img[:,:,1] = cv2.imread('./data/0342/IMG_0342_2.tif', cv2.IMREAD_GRAYSCALE)\n",
    "img[:,:,2] = cv2.imread('./data/0342/IMG_0342_3.tif', cv2.IMREAD_GRAYSCALE)\n",
    "img[:,:,3] = cv2.imread('./data/0342/IMG_0342_4.tif', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "cv2.imshow(\"Registered image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brute-Force Matching with SIFT Descriptors\n",
    "\n",
    "def SIFT(img):\n",
    "    siftDetector= cv2.xfeatures2d.SIFT_create()\n",
    "    kp, des = siftDetector.detectAndCompute(img, None)\n",
    "    return kp, des\n",
    "\n",
    "def matcher(des1, des2): \n",
    "    # create Matcher object\n",
    "    bf_matcher = cv2.BFMatcher()\n",
    "\n",
    "    # Match descriptors.\n",
    "    matches = bf_matcher.match(des1, des2, None)  #Creates a list of all matches, just like keypoints\n",
    "\n",
    "    # Sort them in the order of their distance.\n",
    "    matches = sorted(matches, key = lambda x: x.distance)\n",
    "    return matches\n",
    "\n",
    "def getHomography(matches, kp1, kp2):\n",
    "    points1 = np.zeros((len(matches), 2), dtype=np.float32)  #Prints empty array of size equal to (matches, 2)\n",
    "    points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "    for i, match in enumerate(matches):\n",
    "        points1[i, :] = kp1[match.queryIdx].pt    #gives index of the descriptor in the list of query descriptors\n",
    "        points2[i, :] = kp2[match.trainIdx].pt    #gives index of the descriptor in the list of train descriptors\n",
    "\n",
    "    h, mask = cv2.findHomography(points2, points1, cv2.RANSAC)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated homography : \n",
      " [[ 1.00468876e+00 -4.63354652e-03 -7.42156692e+00]\n",
      " [ 4.66936122e-03  1.00267770e+00  2.53087947e+01]\n",
      " [ 2.10053446e-06 -1.14765900e-06  1.00000000e+00]]\n",
      "Estimated homography : \n",
      " [[ 1.00608470e+00 -3.60006229e-03  1.08584259e+01]\n",
      " [ 5.92347431e-03  1.00419981e+00  2.08415638e+01]\n",
      " [ 3.41684151e-06  1.17436066e-06  1.00000000e+00]]\n",
      "Estimated homography : \n",
      " [[-2.89629100e-01  2.89875718e-02  2.56992303e+02]\n",
      " [-7.46300488e-01 -5.16052248e-01  8.14692651e+02]\n",
      " [-8.73782596e-04 -5.82048430e-04  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "for i in [1,2,3]:\n",
    "    # Find match points\n",
    "    kp1, des1 = SIFT(img[:,:,0])\n",
    "    kp2, des2 = SIFT(img[:,:,i])\n",
    "    matches = matcher(des1, des2)\n",
    "\n",
    "    # Use homography\n",
    "    h = getHomography(matches, kp1, kp2)\n",
    "    height, width, channels = img.shape\n",
    "    img[:,:,i] = cv2.warpPerspective(img[:,:,i], h, (width, height))  #Applies a perspective transformation to an image.\n",
    "\n",
    "    print(\"Estimated homography : \\n\",  h)\n",
    "\n",
    "cv2.imshow(\"Registered image\", img[:,:,:3])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Registered image\", img[:,:,1:4])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brute-Force Matching with SIFT Descriptors\n",
    "\n",
    "def SIFT(img):\n",
    "    siftDetector= cv2.xfeatures2d.SIFT_create()\n",
    "    kp, des = siftDetector.detectAndCompute(img, None)\n",
    "    return kp, des\n",
    "\n",
    "def matcher(des1, des2): \n",
    "    # create Matcher object\n",
    "    bf_matcher = cv2.DescriptorMatcher_create(cv2.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING)\n",
    "\n",
    "    # Match descriptors.\n",
    "    matches = bf_matcher.match(des1, des2, None)  #Creates a list of all matches, just like keypoints\n",
    "\n",
    "    # Sort them in the order of their distance.\n",
    "    matches = sorted(matches, key = lambda x: x.distance)\n",
    "\n",
    "\n",
    "# Draw first 10 matches.\n",
    "img3 = cv2.drawMatches(im1,kp1, im2, kp2, matches[:10], None)\n",
    "\n",
    "cv2.imshow(\"Matches image\", img3)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#Now let us use these key points to register two images. \n",
    "#Can be used for distortion correction or alignment\n",
    "#For this task we will use homography. \n",
    "# https://docs.opencv.org/3.4.1/d9/dab/tutorial_homography.html\n",
    "\n",
    "# Extract location of good matches.\n",
    "# For this we will use RANSAC.\n",
    "#RANSAC is abbreviation of RANdom SAmple Consensus, \n",
    "#in summary it can be considered as outlier rejection method for keypoints.\n",
    "#http://eric-yuan.me/ransac/\n",
    "#RANSAC needs all key points indexed, first set indexed to queryIdx\n",
    "#Second set to #trainIdx. \n",
    "\n",
    "points1 = np.zeros((len(matches), 2), dtype=np.float32)  #Prints empty array of size equal to (matches, 2)\n",
    "points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "for i, match in enumerate(matches):\n",
    "   points1[i, :] = kp1[match.queryIdx].pt    #gives index of the descriptor in the list of query descriptors\n",
    "   points2[i, :] = kp2[match.trainIdx].pt    #gives index of the descriptor in the list of train descriptors\n",
    "\n",
    "#Now we have all good keypoints so we are ready for homography.   \n",
    "# Find homography\n",
    "#https://en.wikipedia.org/wiki/Homography_(computer_vision)\n",
    "  \n",
    "h, mask = cv2.findHomography(points1, points2, cv2.RANSAC)\n",
    " \n",
    "  # Use homography\n",
    "height, width, channels = im2.shape\n",
    "im1Reg = cv2.warpPerspective(im1, h, (width, height))  #Applies a perspective transformation to an image.\n",
    "   \n",
    "print(\"Estimated homography : \\n\",  h)\n",
    "\n",
    "cv2.imshow(\"Registered image\", im1Reg)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
